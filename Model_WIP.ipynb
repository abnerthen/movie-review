{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1NGUYTV7Bkq"
      },
      "source": [
        "## Importing data and testing the actual model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFpKzxBiUV1b",
        "outputId": "2cd4c8b6-90de-40d3-c22a-5dbac7f8d392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpWFFPStftnD"
      },
      "source": [
        "Read in the data and shuffle it using `df.sample`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MALVWR3xYi1M",
        "outputId": "31a3a9bb-c4c9-4ecf-89ed-3af80618ce35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# REMEMBER TO MOUNT THE CSV WHICH CAN BE FOUND IN THE GD\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/IT1244 Project/Movie Review/data.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxM9mDvJfskx"
      },
      "source": [
        "## Preprocessing Data\n",
        "\n",
        "Now that we have taken in the dataset, we ought to preprocess the reviews and perform feature selection to prepare it for our model.\n",
        "\n",
        "Following [this link](https://spotintelligence.com/2022/12/21/nltk-preprocessing-pipeline/), we have a rough idea of what we need to do for preprocessing.\n",
        "\n",
        "1. remove HTML tags\n",
        "2. convert everything to lowercase\n",
        "3. tokenize sentences (to make them easier to vectorize & lemmatize)\n",
        "4. lemmatize the words (reduce words to their base form)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EHGF6KJ6GDbs"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def clean_text(sentence):\n",
        "  # to preprocess it, step by step\n",
        "  # first, remove HTML tags\n",
        "  pattern = r\"<[^>]+>\"\n",
        "  cleaned_text = re.sub(pattern, \"\", sentence)\n",
        "\n",
        "  # next, convert all to lowercase\n",
        "  cleaned_text = cleaned_text.lower()\n",
        "  return cleaned_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VmO_2JIZKALX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(file_path)\n",
        "df['Type'] = np.where(df['Type'] == 'pos', 1, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "bLGemHKZQhYr",
        "outputId": "7e299d03-de2b-4adc-9954-c5748b93537a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Type  Number  Rating                                            Content\n",
              "0         1   20935       9  I just watched \"return from lonesome dove\" and...\n",
              "1         1   12390       8  This movie looked like a classic in the cheesy...\n",
              "2         1    9820       8  Jay Chou plays an orphan raised in a kung fu s...\n",
              "3         1     883       7  Ooverall, the movie was fairly good, a good ac...\n",
              "4         1    9063       8  This movie is fun to watch. If you liked \"Dave...\n",
              "...     ...     ...     ...                                                ...\n",
              "49995     0   16046       1  Anyone remember the first CKY, CKY2K etc..? Ba...\n",
              "49996     0   13620       1  John Madden's cinematic interpretation of Edit...\n",
              "49997     0   16805       1  Lazy movie made by a lazy director. The charac...\n",
              "49998     0   11556       1  I made the big mistake of actually watching th...\n",
              "49999     0   23245       4  Dryly irreverent, but sadly unfunny satire of ...\n",
              "\n",
              "[50000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-adb15971-87db-4978-ab84-24e965acdd45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Number</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20935</td>\n",
              "      <td>9</td>\n",
              "      <td>I just watched \"return from lonesome dove\" and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>12390</td>\n",
              "      <td>8</td>\n",
              "      <td>This movie looked like a classic in the cheesy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>9820</td>\n",
              "      <td>8</td>\n",
              "      <td>Jay Chou plays an orphan raised in a kung fu s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>883</td>\n",
              "      <td>7</td>\n",
              "      <td>Ooverall, the movie was fairly good, a good ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>9063</td>\n",
              "      <td>8</td>\n",
              "      <td>This movie is fun to watch. If you liked \"Dave...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>0</td>\n",
              "      <td>16046</td>\n",
              "      <td>1</td>\n",
              "      <td>Anyone remember the first CKY, CKY2K etc..? Ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>0</td>\n",
              "      <td>13620</td>\n",
              "      <td>1</td>\n",
              "      <td>John Madden's cinematic interpretation of Edit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>0</td>\n",
              "      <td>16805</td>\n",
              "      <td>1</td>\n",
              "      <td>Lazy movie made by a lazy director. The charac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>0</td>\n",
              "      <td>11556</td>\n",
              "      <td>1</td>\n",
              "      <td>I made the big mistake of actually watching th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>0</td>\n",
              "      <td>23245</td>\n",
              "      <td>4</td>\n",
              "      <td>Dryly irreverent, but sadly unfunny satire of ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adb15971-87db-4978-ab84-24e965acdd45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-adb15971-87db-4978-ab84-24e965acdd45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-adb15971-87db-4978-ab84-24e965acdd45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b586497-6e1f-4fbe-b351-72336940b734\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b586497-6e1f-4fbe-b351-72336940b734')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b586497-6e1f-4fbe-b351-72336940b734 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bb62a1c6-1aa4-4be4-a999-6f85d38d6e96\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bb62a1c6-1aa4-4be4-a999-6f85d38d6e96 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7216,\n        \"min\": 1,\n        \"max\": 25000,\n        \"num_unique_values\": 25000,\n        \"samples\": [\n          23310,\n          11603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"Give director Stanley Tong of Jackie Chan's Super Cop and Rumble in the Bronx, and what do you get? You receive a series of kung fu fights and a lack of Magoo-like madness.<br /><br />The limited plot has Magoo (Leslie Nielsen) put into an international plot, where he steals a world-renowned gem. Of course he has no idea what he is doing. In fact, he has no idea that he had the gem.<br /><br />Within thirty minutes you could get very bored watching this. There are some very funny moments though like when he is cooking the chicken. You will wish that you were as nearsighted as Magoo. Its a fun movie to watch but its quite a disaster! You have to love Leslie Nielson because he was made some very funny movies. This isn't his best, but he does a good job playing Magoo. I thought it was a funny film, and it should be recommended to young children because they will probably think that its very funny.\",\n          \"Worst De Niro Scorsese collaboration in this horrible agonizing violent overlong mess. Scorsese is totally out of his element in this film with the horror cliched suddenly loud phone ringing and door slamming gimmicks that seem laughable and embarrassing coming from such a master craftsman. The cast is totally wasted here and the southern accents are very annoying and forced. Nick Noltie plays the wimpiest lawyer in history who would ever believe he can defend anyone ! De Niro's psychotic Bowden is nothing more than the typical 90's movie psycho killer. The scene with De Niro and Lewis early on is very awkward and the climax goes on and on and we should all be more than tired of the on psycho stalker that never dies. One of my most horrible movie experiences. Rent the original it's 100 times better. <br /><br />\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "df['Content'] = df['Content'].apply(clean_text)"
      ],
      "metadata": {
        "id": "C41CHL6UjaA2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use a text embedding layer to create the neural network"
      ],
      "metadata": {
        "id": "oZJkK_sSY2ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "ai8mUhVHY5F9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape = [],\n",
        "                           dtype = tf.string, trainable = True)"
      ],
      "metadata": {
        "id": "5x-pwFRrGRKX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_train, sentences_test, y_train, y_test = train_test_split(df['Content'], df['Type'], test_size=0.5)"
      ],
      "metadata": {
        "id": "5mwV4-rwZaaQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(layers.Dense(16, activation = 'relu'))\n",
        "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVzCiJ81Y8j6",
        "outputId": "e9656713-74cb-45a6-f847-ecb18e0f006c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 50)                48190600  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                816       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48191433 (183.84 MB)\n",
            "Trainable params: 48191433 (183.84 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "aAKQJFYYZIcL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(sentences_train,\n",
        "                    y_train,\n",
        "                    epochs = 10,\n",
        "                    batch_size = 512,\n",
        "                    validation_split = 0.4)"
      ],
      "metadata": {
        "id": "jnqw0p6kZPMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04160c8b-c197-4bfd-9127-0a8df6c45050"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 46s 1s/step - loss: 0.6513 - accuracy: 0.6523 - val_loss: 0.5960 - val_accuracy: 0.7487\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.5225 - accuracy: 0.8045 - val_loss: 0.4752 - val_accuracy: 0.8009\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 44s 1s/step - loss: 0.3859 - accuracy: 0.8581 - val_loss: 0.3821 - val_accuracy: 0.8432\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.2816 - accuracy: 0.8993 - val_loss: 0.3357 - val_accuracy: 0.8605\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 50s 2s/step - loss: 0.2114 - accuracy: 0.9281 - val_loss: 0.3145 - val_accuracy: 0.8678\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 45s 2s/step - loss: 0.1596 - accuracy: 0.9525 - val_loss: 0.3060 - val_accuracy: 0.8722\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 46s 2s/step - loss: 0.1207 - accuracy: 0.9693 - val_loss: 0.3071 - val_accuracy: 0.8727\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 46s 2s/step - loss: 0.0904 - accuracy: 0.9805 - val_loss: 0.3149 - val_accuracy: 0.8720\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 45s 2s/step - loss: 0.0674 - accuracy: 0.9885 - val_loss: 0.3274 - val_accuracy: 0.8713\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 45s 2s/step - loss: 0.0503 - accuracy: 0.9933 - val_loss: 0.3387 - val_accuracy: 0.8681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(sentences_train, y_train,\n",
        "                                batch_size = 256)\n",
        "print('Training loss: {:.4f}'.format(loss))\n",
        "print('Training accuracy: {:.4f}'.format(accuracy))\n",
        "\n",
        "loss, accuracy = model.evaluate(sentences_test, y_test,\n",
        "                                batch_size = 256)\n",
        "print('Testing loss: {:.4f}'.format(loss))\n",
        "print('Testing accuracy: {:.4f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "D0QkdLD7Zum5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac57a9bc-7cdd-422e-e704-d3a16364e126"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 143s 182ms/step - loss: 0.1599 - accuracy: 0.9447\n",
            "Training loss: 0.1599\n",
            "Training accuracy: 0.9447\n",
            "782/782 [==============================] - 167s 214ms/step - loss: 0.3496 - accuracy: 0.8669\n",
            "Testing loss: 0.3496\n",
            "Testing accuracy: 0.8669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatize & Tokenize our Sentences"
      ],
      "metadata": {
        "id": "eAcqmMqbEVHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def token_lemma(cleaned_text):\n",
        "  # next, tokenize the sentence\n",
        "  tokens = nltk.word_tokenize(cleaned_text)\n",
        "  # next, lemmatize the sentence\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "cfcIlS2cETyB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8dWqwDPti5O"
      },
      "source": [
        "# Neural Network using Keras: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "x3kSLCoFtl4O"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform train, test, validation split again as we want to sample new dataset\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train, test = train_test_split(df['Content'], df['Type'], test_size=0.5)\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.4)"
      ],
      "metadata": {
        "id": "lOC9dDdsCVr7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kdQ4JX7etqbk"
      },
      "outputs": [],
      "source": [
        "# even after the text is lemmatized & tokenized by NLTK package, we still need to pass it into a Keras tokenizer layer\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# tokenizer text and create the vocabulary\n",
        "tokenizer = Tokenizer(num_words = 10000, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "X_train_model = tokenizer.texts_to_sequences(sentences_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X_test_model = tokenizer.texts_to_sequences(sentences_test)\n",
        "# Pad the sequences so that they all have the same length\n",
        "X_train_model = pad_sequences(X_train_model, maxlen = 100)\n",
        "X_test_model = pad_sequences(X_test_model, maxlen = 100)"
      ],
      "metadata": {
        "id": "H2-EgKtECns9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim = 10000, output_dim = 64, input_length = 100))\n",
        "model.add(layers.LSTM(units = 64))\n",
        "model.add(layers.Dense(128, activation = 'relu'))\n",
        "model.add(layers.Dense(1, activation = 'sigmoid')) # don't use softmax for binary_crossentropy, worst mistake of my life!!!\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6A6E3TLtDQn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e74b806-507e-46b8-90e7-dc900bd9f5e6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 64)           640000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 681473 (2.60 MB)\n",
            "Trainable params: 681473 (2.60 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "_Cq0RNlyDyFD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_model,\n",
        "          y_train,\n",
        "          batch_size = 512,\n",
        "          epochs = 10,\n",
        "          validation_split = 0.4)"
      ],
      "metadata": {
        "id": "GEpJcXBvD38H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "776b22fa-10c8-4873-f57d-23a86fe461a7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 18s 513ms/step - loss: 0.6601 - accuracy: 0.6389 - val_loss: 0.5127 - val_accuracy: 0.7628\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 16s 555ms/step - loss: 0.3988 - accuracy: 0.8307 - val_loss: 0.3591 - val_accuracy: 0.8399\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 16s 521ms/step - loss: 0.2415 - accuracy: 0.9061 - val_loss: 0.3503 - val_accuracy: 0.8468\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 16s 555ms/step - loss: 0.1720 - accuracy: 0.9399 - val_loss: 0.3870 - val_accuracy: 0.8464\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 17s 578ms/step - loss: 0.1289 - accuracy: 0.9572 - val_loss: 0.4221 - val_accuracy: 0.8386\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 15s 499ms/step - loss: 0.1026 - accuracy: 0.9661 - val_loss: 0.5456 - val_accuracy: 0.8330\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 17s 580ms/step - loss: 0.0708 - accuracy: 0.9799 - val_loss: 0.6117 - val_accuracy: 0.8317\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 21s 710ms/step - loss: 0.0543 - accuracy: 0.9843 - val_loss: 0.7129 - val_accuracy: 0.8257\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 29s 984ms/step - loss: 0.0488 - accuracy: 0.9853 - val_loss: 0.8014 - val_accuracy: 0.8232\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 31s 1s/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.8727 - val_accuracy: 0.8245\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bcfc1c3b430>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_train_model, y_train)\n",
        "print('Training loss: {:.4f}'.format(loss))\n",
        "print('Training accuracy: {:.4f}'.format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test_model, y_test)\n",
        "print('Testing loss: {:.4f}'.format(loss))\n",
        "print('Testing accuracy: {:.4f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "BUA2kdzQEAVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e468bdaa-0c5c-4050-fdf6-91670d4fc172"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 17s 22ms/step - loss: 0.3615 - accuracy: 0.9272\n",
            "Training loss: 0.3615\n",
            "Training accuracy: 0.9272\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.8914 - accuracy: 0.8206\n",
            "Testing loss: 0.8914\n",
            "Testing accuracy: 0.8206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjtRVCfGLbZl"
      },
      "source": [
        "# Using Naive Bayes Classifier\n",
        "\n",
        "Let's try doing this, but with a less computationally expensive classifier: Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_GINAMEx9JC0"
      },
      "outputs": [],
      "source": [
        "# Vectorize the text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features = 5000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to pass lemmatized sentences instead, run this block and not the previous.\n",
        "\n",
        "# sentences_train = sentences_train.apply(token_lemma)\n",
        "# sentences_test = sentences_test.apply(token_lemma)\n",
        "# vectorizer = TfidfVectorizer(max_features = 5000, tokenizer = lambda x: x, lowercase = False)"
      ],
      "metadata": {
        "id": "yU3t-SzVncmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.fit(sentences_train)\n",
        "X_train = vectorizer.transform(sentences_train)\n",
        "X_test = vectorizer.transform(sentences_test)"
      ],
      "metadata": {
        "id": "e4LfDk9Rn12Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "V6mxYPeyLhmj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d250b1f7-0339-4460-dc31-7e77d37ece73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Test Accuracy (TF-IDF): 0.85664\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train) # no need to pick countvectorizer or tfidf as the pipeline will already convert them\n",
        "\n",
        "# nb_count = make_pipeline(count, MultinomialNB())\n",
        "# nb_count.fit(train['Content'], train['Type'])\n",
        "\n",
        "print(\"Train Test Accuracy (TF-IDF):\", accuracy_score(nb_model.predict(X_test),y_test))\n",
        "# print(\"Train Test Accuracy (CountVec)\", accuracy_score(nb_count.predict(test['Content']), test['Type']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comments (Naive Bayes):\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y5VUT-VhqalA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before tokenizing & lemmatizing\n",
        "\n",
        "If I use a Bag-of-Words vectorizer, the accuracy is as follows:\n",
        "```\n",
        "Validation Set : 83.57%\n",
        "Test Set       : 84.144%\n",
        "```\n",
        "\n",
        "If I use TF-IDF Vectorizer, the accuracy is as follows:\n",
        "```\n",
        "Validation Set : 85.315%\n",
        "Test Set       : 86.012%\n",
        "```\n",
        "\n",
        "### After tokenizing & lemmatizing\n",
        "\n",
        "If I use a Bag-of-Words vectorizer, the accuracy is as follows:\n",
        "```\n",
        "Validation Set : 82.36%\n",
        "Test Set       : 82.312%\n",
        "```\n",
        "\n",
        "If I use TF-IDF Vectorizer, the accuracy is as follows:\n",
        "```\n",
        "Validation Set : 84.77%\n",
        "Test Set       : 84.952%\n",
        "```"
      ],
      "metadata": {
        "id": "6dEtNskmrcgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Logistic Regression Classifier"
      ],
      "metadata": {
        "id": "nJ1h27reAk-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression(max_iter = 1000)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"Test accuracy:\", classifier.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "dUN6IGmUAnos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53d5e46-7ff2-41c5-d57d-ea220ca0680f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier = make_pipeline(count, LogisticRegression(max_iter = 1000))\n",
        "# classifier.fit(train['Content'], train['Type'])\n",
        "\n",
        "# print(\"Test accuracy:\", classifier.score(test['Content'], test['Type']))"
      ],
      "metadata": {
        "id": "jA_wItInA5Tt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comments (Logistic Regression)"
      ],
      "metadata": {
        "id": "AlhGyPHurFkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before tokenizing & lemmatizing\n",
        "\n",
        "If I use a Bag-of-Words vectorizer, the accuracy is as follows:\n",
        "```\n",
        "Validation Set : 86.645%\n",
        "Test Set       : 91.884%\n",
        "```\n",
        "\n",
        "If I use TF-IDF Vectorizer, the accuracy is as follows:\n",
        "```\n",
        "Validation Set : 88.68%\n",
        "Test Set       : 90.188%\n",
        "```\n",
        "\n",
        "### After tokenizing & lemmatizing\n",
        "\n",
        "If I use a Bag-of-Words vectorizer, the accuracy is as follows:\n",
        "```\n",
        "Validation Set : 85.5%\n",
        "Test Set       : 85.952%\n",
        "```\n",
        "\n",
        "If I use TF-IDF Vectorizer, the accuracy is as follows:\n",
        "```\n",
        "Validation Set : 87.74%\n",
        "Test Set       : 87.548%\n",
        "```"
      ],
      "metadata": {
        "id": "Z3nYGYLdrfte"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JakOLFCbH8HE"
      },
      "source": [
        "# Neural Network using Keras: Regular Feed Forward using TFIDF Vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general direction of this section comes from this article on practical text classification from the website Real Python.\n",
        "\n",
        "https://realpython.com/python-keras-text-classification/#your-first-keras-model"
      ],
      "metadata": {
        "id": "nE6uu8WGm8Qx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "BifP7htB2jMQ"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KeeV2k4Lj7iT"
      },
      "outputs": [],
      "source": [
        "input_dim = X_train.shape[1]\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim = input_dim, activation = 'relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "DdDRbZfNkH9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ed23d2-ffad-4df2-8794-b30be22a29f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                50010     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50021 (195.39 KB)\n",
            "Trainable params: 50021 (195.39 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHSVVXP_kec2"
      },
      "source": [
        "Now, we test our neural network model to see whether it performs well."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNudVHUF6ix9",
        "outputId": "6070cf94-4382-4f45-a6f1-26518ccaaa61"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "BBZf7mA9keOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c743bdc5-6312-4306-a5e0-b9fb8f47484d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 4s 6ms/step - loss: 0.5384 - accuracy: 0.8109 - val_loss: 0.3899 - val_accuracy: 0.8633\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3086 - accuracy: 0.8921 - val_loss: 0.2964 - val_accuracy: 0.8820\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2365 - accuracy: 0.9135 - val_loss: 0.2747 - val_accuracy: 0.8865\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2019 - accuracy: 0.9250 - val_loss: 0.2715 - val_accuracy: 0.8861\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1788 - accuracy: 0.9349 - val_loss: 0.2774 - val_accuracy: 0.8848\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1613 - accuracy: 0.9435 - val_loss: 0.2846 - val_accuracy: 0.8830\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1477 - accuracy: 0.9481 - val_loss: 0.2952 - val_accuracy: 0.8792\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1358 - accuracy: 0.9543 - val_loss: 0.3098 - val_accuracy: 0.8758\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1257 - accuracy: 0.9591 - val_loss: 0.3241 - val_accuracy: 0.8731\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1169 - accuracy: 0.9629 - val_loss: 0.3408 - val_accuracy: 0.8681\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train.toarray(),  #keras throws a tantrum if you pass a csr matrix to it\n",
        "                    y_train,\n",
        "                    epochs = 10,\n",
        "                    validation_split = 0.4) # it runs pretty fast if you set batch_size to 128, each epoch takes around 5 seconds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ52zx2blWOO"
      },
      "source": [
        "Ok so running the model failed, maybe it's because my dataset is too big. Just leave the other stuff here first.\n",
        "\n",
        "Update 26th March 2024: Change pos/neg to 1/0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "f4DWGzhwkrXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7553ad65-f91d-4b05-c612-1819664bd637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 3s 3ms/step - loss: 0.1962 - accuracy: 0.9316\n",
            "Training loss: 0.1962\n",
            "Training accuracy: 0.9316\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.3363 - accuracy: 0.8725\n",
            "Testing loss: 0.3363\n",
            "Testing accuracy: 0.8725\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_train.toarray(), y_train)\n",
        "print('Training loss: {:.4f}'.format(loss))\n",
        "print('Training accuracy: {:.4f}'.format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test.toarray(), y_test)\n",
        "print('Testing loss: {:.4f}'.format(loss))\n",
        "print('Testing accuracy: {:.4f}'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorizer Neural Network (with Tokenization & Lemmatization) Results!\n",
        "\n",
        "```\n",
        "Training loss       : 0.4187\n",
        "Training accuracy   : 0.9175\n",
        "\n",
        "Validation loss     : 0.4497\n",
        "Validation accuracy : 0.8775\n",
        "\n",
        "Testing loss        : 0.4498\n",
        "Testing accuracy    : 0.8751\n",
        "```\n",
        "\n",
        "CountVectorizer Neural Network (with Tokenization & Lemmatization) Results\n",
        "\n",
        "\n",
        "```\n",
        "Training loss       : 0.4218\n",
        "Training accuracy   : 0.9579\n",
        "\n",
        "Validation loss     : 0.4734\n",
        "Validation accuracy : 0.8776\n",
        "\n",
        "Testing loss        : 0.4730\n",
        "Testing accuracy    : 0.8788\n",
        "```\n"
      ],
      "metadata": {
        "id": "GV8bKEIc6Mhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Word2Vec"
      ],
      "metadata": {
        "id": "wLRBqsy7h-Nq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The source is at https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/#Text_classification_using_Word2Vec_Python\n",
        "\n",
        "First, we preprocess the text data."
      ],
      "metadata": {
        "id": "jW4iTQqeiDco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Word2Vec model\n",
        "from gensim.models import Word2Vec\n",
        "sentences = [sentence.split() for sentence in sentences_train]\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)"
      ],
      "metadata": {
        "id": "SsIsrIVx98do"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "X_train_w2v = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test_w2v = tokenizer.texts_to_sequences(sentences_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "Yev7-ZUl9_EV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the sequences to a fixed length\n",
        "max_length = 100\n",
        "X_train_w2v = pad_sequences(X_train_w2v, maxlen=max_length, padding='post')\n",
        "# X_val_w2v = pad_sequences(X_val_w2v, maxlen=max_length, padding='post')\n",
        "X_test_w2v = pad_sequences(X_test_w2v, maxlen=max_length, padding='post')"
      ],
      "metadata": {
        "id": "W_cGNDlJ-BDb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a weight matrix for the embedding layer\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]"
      ],
      "metadata": {
        "id": "rZRq-r1v-DMe"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "qHPZjyRi-5-c"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(5))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(5))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "k4OLwDSK-GOw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_w2v, y_train, epochs=10, batch_size=512,\n",
        "          validation_split = 0.4)"
      ],
      "metadata": {
        "id": "az-N0bUC-IDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b3f0b7-59c4-4da2-c2c7-0a782628155d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 16s 513ms/step - loss: 0.9690 - accuracy: 0.5180 - val_loss: 0.6677 - val_accuracy: 0.6087\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 16s 545ms/step - loss: 0.6289 - accuracy: 0.6633 - val_loss: 0.6008 - val_accuracy: 0.6793\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 16s 539ms/step - loss: 0.5167 - accuracy: 0.7475 - val_loss: 0.5234 - val_accuracy: 0.7387\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 14s 479ms/step - loss: 0.4436 - accuracy: 0.7904 - val_loss: 0.4921 - val_accuracy: 0.7588\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 14s 481ms/step - loss: 0.3883 - accuracy: 0.8284 - val_loss: 0.4873 - val_accuracy: 0.7677\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 16s 532ms/step - loss: 0.3630 - accuracy: 0.8377 - val_loss: 0.4699 - val_accuracy: 0.7782\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 14s 480ms/step - loss: 0.2933 - accuracy: 0.8835 - val_loss: 0.5015 - val_accuracy: 0.7707\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 15s 503ms/step - loss: 0.2438 - accuracy: 0.9107 - val_loss: 0.5270 - val_accuracy: 0.7590\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 14s 475ms/step - loss: 0.1941 - accuracy: 0.9364 - val_loss: 0.5142 - val_accuracy: 0.7736\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 14s 487ms/step - loss: 0.1434 - accuracy: 0.9593 - val_loss: 0.5751 - val_accuracy: 0.7628\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bcfc1d8b460>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_train_w2v, y_train)\n",
        "print('Training loss: {:.4f}'.format(loss))\n",
        "print('Training accuracy: {:.4f}'.format(accuracy))\n",
        "# loss, accuracy = model.evaluate(X_val_w2v, y_val)\n",
        "# print('Validation loss: {:.4f}'.format(loss))\n",
        "# print('Validation accuracy: {:.4f}'.format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test_w2v, y_test)\n",
        "print('Testing loss: {:.4f}'.format(loss))\n",
        "print('Testing accuracy: {:.4f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "EKF7EKJM-KAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40ac4a4-ed08-4413-98f4-81b45205db60"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 10s 12ms/step - loss: 0.2957 - accuracy: 0.8924\n",
            "Training loss: 0.2957\n",
            "Training accuracy: 0.8924\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.5691 - accuracy: 0.7637\n",
            "Testing loss: 0.5691\n",
            "Testing accuracy: 0.7637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final comments"
      ],
      "metadata": {
        "id": "Gmv7qHahfnhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A neural network where the first layer is a text embedding model seems to take the longest to fit. This could be blamed on the fact that the text embedding model takes in many parameters (48 million!) compared to other neural network models taking in vectors."
      ],
      "metadata": {
        "id": "t-5kpFclf7Y_"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WxM9mDvJfskx",
        "oZJkK_sSY2ED",
        "eAcqmMqbEVHM",
        "F8dWqwDPti5O",
        "AlhGyPHurFkR",
        "Gmv7qHahfnhb"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}